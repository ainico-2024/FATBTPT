import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import os

# Paths to your dataset
train_dir = '/content/drive/MyDrive/demo/train'
val_dir = '/content/drive/MyDrive/demo/val'

# Image dimensions
img_width, img_height = 224, 224  # VGG16 expects 224x224 images

# Create data generators for loading and augmenting images
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_width, img_height),
    batch_size=10,  # Smaller batch size for small dataset
    class_mode='binary',
    shuffle=True  # Shuffle the data
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(img_width, img_height),
    batch_size=10,  # Smaller batch size for small dataset
    class_mode='binary',
    shuffle=False  # No need to shuffle validation data
)

# Check the data generators
print("Training samples:", train_generator.samples)
print("Validation samples:", val_generator.samples)
print("Batch size:", train_generator.batch_size)
print("Class indices:", train_generator.class_indices)

# Verify data loading
x_batch, y_batch = next(train_generator)
print("Batch shape:", x_batch.shape)
print("Labels shape:", y_batch.shape)

# Load VGG16 model with pretrained weights
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom layers on top of VGG16
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dense(1, activation='sigmoid')(x)  # Binary classification

# Create the final model
model = Model(inputs=base_model.input, outputs=x)

# Compile the model
model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

# Compute steps per epoch and validation steps
steps_per_epoch = max(1, train_generator.samples // train_generator.batch_size)
validation_steps = max(1, val_generator.samples // val_generator.batch_size)

print(f"Steps per epoch: {steps_per_epoch}")
print(f"Validation steps: {validation_steps}")

# Ensure these values are not zero
if steps_per_epoch == 0 or validation_steps == 0:
    raise ValueError("The number of steps per epoch or validation steps is zero.")

# Check if val_generator yields any files
file_count = 0
for file in val_generator.filenames:
    file_count += 1

if file_count == 0:
    raise ValueError("Validation generator did not yield any files. Check the path and data organization.")

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=10,
    validation_data=val_generator,
    validation_steps=validation_steps
)

# Save the model
model.save('vgg16_finetuned.h5')

# Evaluate the model
val_loss, val_acc = model.evaluate(val_generator)
print(f'Validation loss: {val_loss}')
print(f'Validation accuracy: {val_acc}')




import matplotlib.pyplot as plt

# Extract history from the training process
history = history  # This is the variable where `model.fit()` result is stored

# Plot training & validation accuracy values
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Training Accuracy', 'Validation Accuracy'])

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Training Loss', 'Validation Loss'])

plt.tight_layout()
plt.show()
