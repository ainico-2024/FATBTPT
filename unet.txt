import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Set up the data generators
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalize pixel values
)

val_datagen = ImageDataGenerator(
    rescale=1./255
)

# Define data generators
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/demo/train',
    target_size=(128, 128),
    batch_size=32,
    class_mode='input',  # Change to 'input' for image segmentation
    color_mode='grayscale'
)

val_generator = val_datagen.flow_from_directory(
    '/content/drive/MyDrive/demo/val',
    target_size=(128, 128),
    batch_size=32,
    class_mode='input',  # Change to 'input' for image segmentation
    color_mode='grayscale'
)




from tensorflow.keras import layers, models

def unet_model(input_shape):
    inputs = layers.Input(shape=input_shape)

    # Encoder
    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = layers.MaxPooling2D((2, 2))(conv1)

    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling2D((2, 2))(conv2)

    # Bottleneck
    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)

    # Decoder
    up4 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv3)
    concat4 = layers.concatenate([up4, conv2], axis=-1)
    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(concat4)
    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)

    up5 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4)
    concat5 = layers.concatenate([up5, conv1], axis=-1)
    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat5)
    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)

    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv5)

    model = models.Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

input_shape = (128, 128, 1)  # Adjust for grayscale images
model = unet_model(input_shape)




steps_per_epoch = 10
 validation_steps = 10

 history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch // train_generator.batch_size,
    epochs=10,  # Adjust as needed
    validation_data=val_generator,
    validation_steps=validation_steps  // val_generator.batch_size
)

